{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoramento de Entrada e Saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import face_recognition\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializar a url de acesso a api\n",
    "base_url = 'http://localhost:3333'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'd3e3b8ea-788d-45d5-bca3-4027c2728715',\n",
       "  'name': 'Laciene Garcia',\n",
       "  'avatar_url': 'http://localhost:3333/uploads/54ac0182d235-laciene2.jpeg'},\n",
       " {'id': '4ba22232-b5aa-474a-91a6-6898abd3ab27',\n",
       "  'name': 'Leonardo Gonçalves',\n",
       "  'avatar_url': 'http://localhost:3333/uploads/1c9ce47f65b0-perfil-leo.jpeg'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listar os usuários cadastrados\n",
    "response = requests.get(f'{base_url}/user/list')\n",
    "users = response.json()\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_faces = []\n",
    "\n",
    "# preparar lista de objetos\n",
    "for user in users:\n",
    "    image_link = user['avatar_url']\n",
    "\n",
    "    # baixar image\n",
    "    fetch_image = requests.get(image_link)\n",
    "    binary_encoding = BytesIO(fetch_image.content)\n",
    "\n",
    "    # converter para o formato aceito pelo face-recognition\n",
    "    convert_to_RGB = Image.open(binary_encoding).convert(\"RGB\")\n",
    "    convert_to_array = np.array(convert_to_RGB)\n",
    "\n",
    "    # codificar imagem\n",
    "    facial_encoding = face_recognition.face_encodings(convert_to_array)[0]\n",
    "\n",
    "    # adicionar a lista de objetos\n",
    "    known_faces.append({ 'id': user['id'], 'face_encoding': facial_encoding, 'name': user['name']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciar a webcam\n",
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 30.05it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.22it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.63it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 29.02it/s]\n",
      "2025-01-10 20:50:33.260 Python[19401:50184776] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-10 20:50:33.260 Python[19401:50184776] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.19it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.20it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.76it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.37it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.84it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 29.49it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 29.45it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.44it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 37.57it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.54it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.83it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.93it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 37.63it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.04it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.64it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 28.83it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 29.63it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.77it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.17it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.56it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 30.41it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.77it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.40it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.97it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.59it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.19it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.33it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 30.59it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.96it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 29.05it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.18it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.54it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.95it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 29.74it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.19it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.11it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.45it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 38.31it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 28.39it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.53it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.50it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.51it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.33it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.42it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 30.42it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.05it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.79it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 27.54it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.83it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 22.94it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.06it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.23it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.22it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.49it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.81it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.98it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 37.74it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.51it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.72it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.46it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.53it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 37.10it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.46it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.05it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.16it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 38.64it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 37.44it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 37.69it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.56it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.25it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.39it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.56it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.64it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.72it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.42it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.67it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.79it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.11it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.59it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.07it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 17.64it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.50it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.00it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.94it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.45it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.91it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.23it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.97it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 29.02it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 29.14it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.29it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 30.38it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.49it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 29.96it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.30it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.74it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.37it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 37.78it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.16it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.76it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.34it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.47it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.85it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 37.21it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.03it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.30it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.98it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.76it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.39it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.41it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 34.17it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.97it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.19it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 36.86it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 33.28it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 35.93it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 32.97it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 29.74it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 31.29it/s]\n",
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 27.98it/s]\n",
      "Action: emotion:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "while True: \n",
    "    # capturando um frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # encontra face no frame\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # demarcar o rosto com um quadrado\n",
    "        cv2.rectangle(img=frame, pt1=(left, top), pt2=(right, bottom), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # verifica se as faces correspondem\n",
    "        in_matched = face_recognition.compare_faces([user['face_encoding'] for user in known_faces], face_encoding)\n",
    "\n",
    "        name, user_id = \"Desconhecido\", None\n",
    "        if(True in in_matched):\n",
    "            index = in_matched.index(True)\n",
    "            user_id = known_faces[index]['id']\n",
    "            name = known_faces[index]['name']\n",
    "\n",
    "            # região de interesse\n",
    "            roi = frame[max(0, top):min(frame.shape[0], bottom), max(0, left):min(frame.shape[1], right)]\n",
    "            emotion = DeepFace.analyze(roi, actions=\"emotion\", enforce_detection=False)[0][\"dominant_emotion\"]\n",
    "\n",
    "            # registrar presença\n",
    "            requests.post(f'{base_url}/presence/create', \n",
    "                          json={\"user_id\": user_id, \"mood\": emotion}\n",
    "                          )\n",
    "            \n",
    "            # adicionar as identificações do frame\n",
    "            font, scale, color, thickness = cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255), 1\n",
    "\n",
    "            # adicionar as identificações no frame\n",
    "            cv2.putText(img=frame, text=f'id: {user_id}', org=(left + 6, bottom + 20), fontFace=font, fontScale=scale, color=color, thickness=thickness)\n",
    "            cv2.putText(img=frame, text=f'name: {name}', org=(left + 6, bottom + 40), fontFace=font, fontScale=scale, color=color, thickness=thickness)\n",
    "            cv2.putText(img=frame, text=f'emotion: {emotion}', org=(left + 6, bottom + 60), fontFace=font, fontScale=scale, color=color, thickness=thickness)\n",
    "\n",
    "    # mostrar o frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # sair do loop\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "\n",
    "# liberar recursos\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual-environment",
   "language": "python",
   "name": "virtual-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
